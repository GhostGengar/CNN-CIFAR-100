{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network on CIFAR-100 Dataset\n",
    "Author: **Tien Dinh**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This is a model built using Tensorflow. The model was trained on the CIFAR-100 Dataset for 5000 times. I was able to get around 50% of accuracy, which is pretty reasonable since the data has only 500 images per class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "* [Learning Multiple Layers of Features from Tiny Images](https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf), Alex Krizhevsky, 2009."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First we are going to get the data and prepare it for training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR_DIR = 'cifar-100-python/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        cifar_dict = pickle.load(fo, encoding='bytes')\n",
    "    return cifar_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = ['meta', 'test', 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = [0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,direc in zip(all_data,dirs):\n",
    "    all_data[i] = unpickle(CIFAR_DIR+direc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = all_data[0]\n",
    "test_data = all_data[1]\n",
    "train_data = all_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([b'fine_label_names', b'coarse_label_names'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([b'batch_label', b'filenames', b'coarse_labels', b'fine_labels', b'data'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using matplotlib to visualize the images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3072)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[b'data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test_data[b'data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(10000, 3, 32, 32).transpose(0, 2, 3, 1).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10edc8e80>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1091664e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[1012])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(vec, vals):\n",
    "    '''\n",
    "    One hot encode the output labels to be numpy arrays of 0s and 1s\n",
    "    '''\n",
    "    n = len(vec)\n",
    "    out = np.zeros((n, vals))\n",
    "    out[range(n), vec] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a helper class which is used to grab batches to feed into the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarHelper():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.i = 0\n",
    "        \n",
    "        self.train_batch = [train_data]\n",
    "        self.test_batch = [test_data]\n",
    "        \n",
    "        self.training_images = None\n",
    "        self.training_labels = None\n",
    "        \n",
    "        self.testing_images = None\n",
    "        self.testing_labels = None\n",
    "        \n",
    "    def set_up_images(self):\n",
    "        \n",
    "        print('Setting Up Training Images and Labels')\n",
    "        \n",
    "        self.training_images = np.vstack([d[b'data'] for d in self.train_batch])\n",
    "        train_len = len(self.training_images)\n",
    "        \n",
    "        self.training_images = self.training_images.reshape(train_len, 3, 32, 32).transpose(0, 2, 3, 1) / 255\n",
    "        self.training_labels = one_hot_encode(np.hstack([d[b'coarse_labels'] for d in self.train_batch]), 20)\n",
    "        \n",
    "        print('Setting Up Testing Images and Labels')\n",
    "        \n",
    "        self.testing_images = np.vstack([d[b'data'] for d in self.test_batch])\n",
    "        test_len = len(self.testing_images)\n",
    "        \n",
    "        self.testing_images = self.testing_images.reshape(test_len, 3, 32, 32).transpose(0, 2, 3, 1) / 255\n",
    "        self.testing_labels = one_hot_encode(np.hstack([d[b'coarse_labels'] for d in self.test_batch]), 20)\n",
    "        \n",
    "    def next_batch(self, batch_size):\n",
    "        x = self.training_images[self.i:self.i + batch_size].reshape(batch_size, 32, 32, 3)\n",
    "        y = self.training_labels[self.i:self.i + batch_size]\n",
    "        self.i = (self.i + batch_size) % len(self.training_images)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Up Training Images and Labels\n",
      "Setting Up Testing Images and Labels\n"
     ]
    }
   ],
   "source": [
    "ch = CifarHelper()\n",
    "ch.set_up_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None,32,32,3])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)\n",
    "\n",
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W) + b)\n",
    "\n",
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_1 = convolutional_layer(x, shape=[4,4,3,32])\n",
    "convo_1_pooling = max_pool_2by2(convo_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_2 = convolutional_layer(convo_1_pooling, shape=[4,4,32,64])\n",
    "convo_2_pooling = max_pool_2by2(convo_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_2_flat = tf.reshape(convo_2_pooling, [-1, 8*8*64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_one_dropout = tf.nn.dropout(full_layer_one, keep_prob=hold_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = normal_full_layer(full_one_dropout, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Step 0\n",
      "Accuracy is: \n",
      "0.0609\n",
      "\n",
      "\n",
      "On Step 100\n",
      "Accuracy is: \n",
      "0.2\n",
      "\n",
      "\n",
      "On Step 200\n",
      "Accuracy is: \n",
      "0.2474\n",
      "\n",
      "\n",
      "On Step 300\n",
      "Accuracy is: \n",
      "0.3072\n",
      "\n",
      "\n",
      "On Step 400\n",
      "Accuracy is: \n",
      "0.3118\n",
      "\n",
      "\n",
      "On Step 500\n",
      "Accuracy is: \n",
      "0.3396\n",
      "\n",
      "\n",
      "On Step 600\n",
      "Accuracy is: \n",
      "0.3385\n",
      "\n",
      "\n",
      "On Step 700\n",
      "Accuracy is: \n",
      "0.3497\n",
      "\n",
      "\n",
      "On Step 800\n",
      "Accuracy is: \n",
      "0.3743\n",
      "\n",
      "\n",
      "On Step 900\n",
      "Accuracy is: \n",
      "0.3792\n",
      "\n",
      "\n",
      "On Step 1000\n",
      "Accuracy is: \n",
      "0.3906\n",
      "\n",
      "\n",
      "On Step 1100\n",
      "Accuracy is: \n",
      "0.3887\n",
      "\n",
      "\n",
      "On Step 1200\n",
      "Accuracy is: \n",
      "0.4051\n",
      "\n",
      "\n",
      "On Step 1300\n",
      "Accuracy is: \n",
      "0.416\n",
      "\n",
      "\n",
      "On Step 1400\n",
      "Accuracy is: \n",
      "0.416\n",
      "\n",
      "\n",
      "On Step 1500\n",
      "Accuracy is: \n",
      "0.4257\n",
      "\n",
      "\n",
      "On Step 1600\n",
      "Accuracy is: \n",
      "0.4387\n",
      "\n",
      "\n",
      "On Step 1700\n",
      "Accuracy is: \n",
      "0.4309\n",
      "\n",
      "\n",
      "On Step 1800\n",
      "Accuracy is: \n",
      "0.4422\n",
      "\n",
      "\n",
      "On Step 1900\n",
      "Accuracy is: \n",
      "0.4392\n",
      "\n",
      "\n",
      "On Step 2000\n",
      "Accuracy is: \n",
      "0.4518\n",
      "\n",
      "\n",
      "On Step 2100\n",
      "Accuracy is: \n",
      "0.4585\n",
      "\n",
      "\n",
      "On Step 2200\n",
      "Accuracy is: \n",
      "0.4573\n",
      "\n",
      "\n",
      "On Step 2300\n",
      "Accuracy is: \n",
      "0.4648\n",
      "\n",
      "\n",
      "On Step 2400\n",
      "Accuracy is: \n",
      "0.4633\n",
      "\n",
      "\n",
      "On Step 2500\n",
      "Accuracy is: \n",
      "0.4615\n",
      "\n",
      "\n",
      "On Step 2600\n",
      "Accuracy is: \n",
      "0.4803\n",
      "\n",
      "\n",
      "On Step 2700\n",
      "Accuracy is: \n",
      "0.4721\n",
      "\n",
      "\n",
      "On Step 2800\n",
      "Accuracy is: \n",
      "0.4755\n",
      "\n",
      "\n",
      "On Step 2900\n",
      "Accuracy is: \n",
      "0.467\n",
      "\n",
      "\n",
      "On Step 3000\n",
      "Accuracy is: \n",
      "0.4785\n",
      "\n",
      "\n",
      "On Step 3100\n",
      "Accuracy is: \n",
      "0.4781\n",
      "\n",
      "\n",
      "On Step 3200\n",
      "Accuracy is: \n",
      "0.4768\n",
      "\n",
      "\n",
      "On Step 3300\n",
      "Accuracy is: \n",
      "0.4799\n",
      "\n",
      "\n",
      "On Step 3400\n",
      "Accuracy is: \n",
      "0.4825\n",
      "\n",
      "\n",
      "On Step 3500\n",
      "Accuracy is: \n",
      "0.4852\n",
      "\n",
      "\n",
      "On Step 3600\n",
      "Accuracy is: \n",
      "0.4736\n",
      "\n",
      "\n",
      "On Step 3700\n",
      "Accuracy is: \n",
      "0.4771\n",
      "\n",
      "\n",
      "On Step 3800\n",
      "Accuracy is: \n",
      "0.4793\n",
      "\n",
      "\n",
      "On Step 3900\n",
      "Accuracy is: \n",
      "0.4739\n",
      "\n",
      "\n",
      "On Step 4000\n",
      "Accuracy is: \n",
      "0.4835\n",
      "\n",
      "\n",
      "On Step 4100\n",
      "Accuracy is: \n",
      "0.4984\n",
      "\n",
      "\n",
      "On Step 4200\n",
      "Accuracy is: \n",
      "0.4831\n",
      "\n",
      "\n",
      "On Step 4300\n",
      "Accuracy is: \n",
      "0.4821\n",
      "\n",
      "\n",
      "On Step 4400\n",
      "Accuracy is: \n",
      "0.4839\n",
      "\n",
      "\n",
      "On Step 4500\n",
      "Accuracy is: \n",
      "0.4755\n",
      "\n",
      "\n",
      "On Step 4600\n",
      "Accuracy is: \n",
      "0.4907\n",
      "\n",
      "\n",
      "On Step 4700\n",
      "Accuracy is: \n",
      "0.4777\n",
      "\n",
      "\n",
      "On Step 4800\n",
      "Accuracy is: \n",
      "0.4839\n",
      "\n",
      "\n",
      "On Step 4900\n",
      "Accuracy is: \n",
      "0.4797\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(5000):\n",
    "        x_batch, y_batch = ch.next_batch(100)\n",
    "        sess.run(train, feed_dict={x:x_batch, y_true:y_batch, hold_prob:0.5})\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print('On Step {}'.format(i))\n",
    "            print('Accuracy is: ')\n",
    "            matches = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "            acc = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "            \n",
    "            print(sess.run(acc, feed_dict={x:ch.testing_images, y_true:ch.testing_labels, hold_prob:1.0}))\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Accuracy: 47.97%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
